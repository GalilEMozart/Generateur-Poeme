{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation des poemes en Francais\n",
    "---\n",
    "Auteur: Yves SAIDO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan\n",
    "\n",
    "0. [Introduction](#part0)\n",
    "1. [Récupération des données et constitution du dataset](#part1)\n",
    "2. [Nettoyage de données ](#part2)\n",
    "3. [Entrainement des 2 modèles de génération de données](#part3)\n",
    "4. [Génération de quelques exemples avec les modèles entrainés](#part4)\n",
    "5. [Conclusion  et analyses des résultats](#part5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Introduction <a id=\"part0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce projet est d'entrainer un modèle de génération de poèmes. Pour ce faire, nous n'allons pas entrainer ce premier modèle from scratch, nous allons fine-tuning le modèle GPT-2 (celui entrainé sur les données en français), puis nous allons sur-entrainer (fine-tuning) sur notre jeu de données. GPT-2 ne sera pas le seul modèle que nous allons entrainer, nous entrainerons aussi un autre modèle (RNN) pour générer les poèmes. \n",
    "\n",
    "Nous allons faire alors un comparatif de ces 2 modèles sur le cout d'entrainement, le temps, le texte générés, etc Nous expliquerons les choix faits, les difficultés rencontrées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Récupération des données et constitution du dataset <a id=\"part1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons répertorié plusieurs sites dont certains publient régulièrement des poèmes en français postés par des personnes lambdas, certains répertorient les poèmes déjà connus du grand public, des classiques. Notre choix s'est porté sur ce [site](www.poeme-france.com) qui offre des poèmes écrits par des personnes lambdas, et des grands classiques aussi. Nous aurions pu scraper plus de site si la puissance de calculs était à notre disposition, pour constituer un dataset beaucoup plus grand que ce que nous avons eu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons écrit principalement 4 fonctions pour cette partie concernant la récupération des données. La documentation est bien fournie pour plus de détails, mais donnons un bref résumé des fonctions :\n",
    "- content_page_poeme: \n",
    "- get_all_poeme_for_theme:\n",
    "- get_all_data:\n",
    "- create_dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from multiprocessing.dummy import Pool\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_page_poeme(links):\n",
    "    \"\"\"\n",
    "    Récupère tout le contenu d'une page depuis le lien links\n",
    "\n",
    "    Args:\n",
    "        links (str): lien vers la page contenant le poème\n",
    "    Returns:\n",
    "        string: retourne un poème en chaine de caractères\n",
    "    \"\"\"\n",
    "\n",
    "    page = requests.get(links)\n",
    "    \n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    poem_title = soup.find_all(class_=\"PoemTitre\")[0].contents[0]\n",
    "    poem_content = soup.find_all(id='lePoeme')[0].contents\n",
    " \n",
    "    n = len(poem_content)\n",
    "    poem_content = [str(e) if str(e)!='<br/>' else '\\n' for e in poem_content ]    \n",
    "\n",
    "    return poem_title, ''.join(poem_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_poeme_for_theme(links,root = \"https://www.poeme-france.com\"):\n",
    "    \"\"\"\n",
    "    Récupère tous d'un thème depuis le lien links\n",
    "\n",
    "    Args:\n",
    "        links (str): lien vers les poèmes d'un thème pointe par le lien\n",
    "    Returns:\n",
    "        list: liste de tous les poèmes du thème pointe par le lien\n",
    "    \"\"\"    \n",
    "    \n",
    "    page = requests.get(root+links)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')    \n",
    "\n",
    "    # find the numbre of pas for this theme\n",
    "    n = len(soup.find_all(id='example1')[0].find_all(class_='pagination text-center')[0].find_all('li'))\n",
    "    \n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for i in range(n):\n",
    "        \n",
    "        page = requests.get(f'{root}{links};{i}')\n",
    "\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        all_title_poeme = soup.find_all(id='example1')[0]\n",
    "        all_title_poeme = all_title_poeme.find_all(class_='pLeft clearfix')\n",
    "        all_title_poeme = [ title.find_all('a')[0].attrs['href'] for title in all_title_poeme]\n",
    "\n",
    "        #all_data.extend(all_title_poeme)\n",
    "\n",
    "\n",
    "        for poeme in all_title_poeme:\n",
    "            poem_text = content_page_poeme(root+poeme)\n",
    "            all_data.append(poem_text)\n",
    "            \n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data():\n",
    "    \"\"\"\n",
    "    Récupère tous les poèmes du site www.poeme-france.com\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "    Returns:\n",
    "        dict: retourne un dictionnaire dont chaque clé est un thème et la valeur de la clé est une liste des poèmes.\n",
    "    \"\"\"\n",
    "    root = \"https://www.poeme-france.com\"\n",
    "    \n",
    "    \n",
    "    #get all theme\n",
    "    page = requests.get(root+'/liste-poemes/theme')\n",
    "\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    theme_id = soup.find_all(id='example1')\n",
    "    \n",
    "    all_theme = theme_id[0].find_all(class_=\"button small w49\")\n",
    "    all_theme = [theme.attrs['href'] for theme in all_theme ] \n",
    "\n",
    "    p = Pool(multiprocessing.cpu_count())\n",
    "\n",
    "    #get page of theme\n",
    "    all_data = {}\n",
    "    all_theme = all_theme[:10]\n",
    "    \n",
    "    q = multiprocessing.Queue()\n",
    "    #return_dict = manager.dict()\n",
    "\n",
    "\n",
    "    all_process = [root + k for k in all_theme]\n",
    "    result = p.map(get_all_poeme_for_theme, all_process)\n",
    "    \n",
    "    for i,(them,cont) in enumerate(zip(all_theme,result)):\n",
    "        all_data[them.split('/')[-1]] = cont\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    for i,theme in enumerate(all_theme):\n",
    "        \n",
    "        #print(root+theme)\n",
    "        #res = threading.Thread(target=get_all_poeme_for_theme,args=(root+theme,))\n",
    "        res = p.map(get_all_poeme_for_theme, root+theme)\n",
    "        #res = multiprocessing.Process(target=get_all_poeme_for_theme, args=(root+theme,q,i))\n",
    "        res.start()\n",
    "        #print('NEXT NEXT', theme)\n",
    "        all_data_mulitprocess.append(res)\n",
    "        #for poeme in res:\n",
    "        #    poem_text = content_page_poeme(root+poeme)\n",
    "        #    poemes.append(poem_text)\n",
    "            \n",
    "\n",
    "        #all_data[theme.split('/')[-1]] = res\n",
    "        #print(all_data) \n",
    "     \n",
    "    #p.close()\n",
    "    #for t in all_data_mulitprocess:\n",
    "        t.join()\n",
    "    \n",
    "    #print('RES',res)\n",
    "    # vider la file\n",
    "    #n = len(all_theme)\n",
    "    #data = [None for _ in range(n)]\n",
    "    #print('before here')\n",
    "\n",
    "    #print('first get',q.get(1))\n",
    "    #while q.empty() is True:\n",
    "        print('here')\n",
    "        res = q.get()\n",
    "        print(res)\n",
    "        data[res[0]] = res[1]\n",
    "\n",
    "    for i,t in enumerate(all_theme):\n",
    "        all_data[t.split('/')[-1]] = data[i]\n",
    "\n",
    "    \n",
    "    executor =  concurrent.futures.ProcessPoolExecutor()\n",
    "    result = executor.map(get_all_poeme_for_theme, all_theme[:3])\n",
    "    \n",
    "    \n",
    "    #for v in result:\n",
    "    #    print(v.result())\n",
    "    #create dataframe pandas and save it\n",
    "    \"\"\"\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def them_b_process(themes):\n",
    "    \"\"\" Fonction qui est utilisé dans la fonction get_all_data pour l'optimiser \"\"\"\n",
    "    data = {}\n",
    "    for theme in themes:\n",
    "        data[theme] = get_all_poeme_for_theme(theme)\n",
    "\n",
    "    return data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"https://www.poeme-france.com\"\n",
    "\n",
    "\n",
    "#get all theme\n",
    "page = requests.get(root+'/liste-poemes/theme')\n",
    "\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "theme_id = soup.find_all(id='example1')\n",
    "\n",
    "all_theme = theme_id[0].find_all(class_=\"button small w49\")\n",
    "all_theme = [theme.attrs['href'] for theme in all_theme ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(all_theme):\n",
    "    \"\"\"\n",
    "    Récupère tous les poèmes du site www.poeme-france.com\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "    Returns:\n",
    "        dict: retourne un dictionnaire dont chaque clé est un thème et la valeur de la clé est une liste des poèmes.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\" \n",
    "    root = \"https://www.poeme-france.com\"\n",
    "    \n",
    "    \n",
    "    #get all theme\n",
    "    page = requests.get(root+'/liste-poemes/theme')\n",
    "\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    theme_id = soup.find_all(id='example1')\n",
    "    \n",
    "    all_theme = theme_id[0].find_all(class_=\"button small w49\")\n",
    "    all_theme = [theme.attrs['href'] for theme in all_theme ] \n",
    "    \"\"\"\n",
    "    p = Pool(multiprocessing.cpu_count()-1)\n",
    "    \n",
    "    #get page of theme\n",
    "    all_data = defaultdict(list)\n",
    "    #all_theme = all_theme[:150]\n",
    "    \n",
    "\n",
    "    k = len(range(0, len(all_theme), multiprocessing.cpu_count()-1))\n",
    "    chunk = [all_theme[i:i + k] for i in range(0, len(all_theme), k)]\n",
    "    \n",
    "    results = p.map(them_b_process,chunk)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    \n",
    "    for elt in results:\n",
    "        for key, value in elt.items():\n",
    "            all_data[key].extend(value)    \n",
    "\n",
    "    return dict(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = get_all_data(all_theme[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = get_all_data(all_theme[100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res3 = get_all_data(all_theme[200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 83)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res1),len(res2),len(res3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(datas):\n",
    "    \"\"\"\n",
    "    Récupère tous les poèmes du site www.poeme-france.com\n",
    "\n",
    "    Args:\n",
    "        dict: retourne un dictionnaire dont chaque clé est un thème et la valeur de la clé est une liste des poèmes.\n",
    "    Returns:\n",
    "        pandas : retourne une dataFrame\n",
    "    \"\"\"\n",
    "    theme = []\n",
    "    text = []\n",
    "    titre = []\n",
    "    for data in datas:\n",
    "        for key, value in data.items():\n",
    "            for tit, tex in value:\n",
    "                theme.append(key)\n",
    "                text.append(tex)\n",
    "                titre.append(tit)\n",
    "    \n",
    "    return pd.DataFrame(\n",
    "        data={\n",
    "            'theme': theme,\n",
    "            'texte': text,\n",
    "            'titre': titre\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = create_dataframe([res1,res2,res3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theme</th>\n",
       "      <th>texte</th>\n",
       "      <th>titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/liste-poemes/theme/abondance</td>\n",
       "      <td>Après la tempête vient le ciel bleu\\nAprès la ...</td>\n",
       "      <td>La Perle De Dieu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/liste-poemes/theme/abondance</td>\n",
       "      <td>Au « Logis du p’tit Canette », le 11 octobre 2...</td>\n",
       "      <td>Quand La Lune Se Dessine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/liste-poemes/theme/abondance</td>\n",
       "      <td>Le linceul de mes songes dérives lentement\\nLa...</td>\n",
       "      <td>Nouveau Souffle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/liste-poemes/theme/abondance</td>\n",
       "      <td>Très jaune de lueurs,\\nSur cette faune en sueu...</td>\n",
       "      <td>Ces Étoiles Qui Brillent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/liste-poemes/theme/abondance</td>\n",
       "      <td>Avant j’avais toujours la tete,\\nDans les étoi...</td>\n",
       "      <td>Je Veux Dire Adieux Juste Instant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36474</th>\n",
       "      <td>/liste-poemes/theme/voyage</td>\n",
       "      <td>C’est une île dans les antilles ;\\nArchipel de...</td>\n",
       "      <td>Union</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36475</th>\n",
       "      <td>/liste-poemes/theme/voyage</td>\n",
       "      <td>Sur mon cœur, tes larmes, tu as déposé\\nPour m...</td>\n",
       "      <td>Un Voyage Pour Le Paradis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36476</th>\n",
       "      <td>/liste-poemes/theme/voyage</td>\n",
       "      <td>Marchons à deux sur ce chemin,\\nSous le soleil...</td>\n",
       "      <td>Un Amour Sans Limites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36477</th>\n",
       "      <td>/liste-poemes/theme/voyage</td>\n",
       "      <td>Tu vas voyager\\nPour longtemps, t’éloigner\\nUn...</td>\n",
       "      <td>Le Voyage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36478</th>\n",
       "      <td>/liste-poemes/theme/voyage</td>\n",
       "      <td>Pour toi la maman\\nAvec tes enfants\\n\\nJe vais...</td>\n",
       "      <td>Un Petit Voyage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36479 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               theme  \\\n",
       "0      /liste-poemes/theme/abondance   \n",
       "1      /liste-poemes/theme/abondance   \n",
       "2      /liste-poemes/theme/abondance   \n",
       "3      /liste-poemes/theme/abondance   \n",
       "4      /liste-poemes/theme/abondance   \n",
       "...                              ...   \n",
       "36474     /liste-poemes/theme/voyage   \n",
       "36475     /liste-poemes/theme/voyage   \n",
       "36476     /liste-poemes/theme/voyage   \n",
       "36477     /liste-poemes/theme/voyage   \n",
       "36478     /liste-poemes/theme/voyage   \n",
       "\n",
       "                                                   texte  \\\n",
       "0      Après la tempête vient le ciel bleu\\nAprès la ...   \n",
       "1      Au « Logis du p’tit Canette », le 11 octobre 2...   \n",
       "2      Le linceul de mes songes dérives lentement\\nLa...   \n",
       "3      Très jaune de lueurs,\\nSur cette faune en sueu...   \n",
       "4      Avant j’avais toujours la tete,\\nDans les étoi...   \n",
       "...                                                  ...   \n",
       "36474  C’est une île dans les antilles ;\\nArchipel de...   \n",
       "36475  Sur mon cœur, tes larmes, tu as déposé\\nPour m...   \n",
       "36476  Marchons à deux sur ce chemin,\\nSous le soleil...   \n",
       "36477  Tu vas voyager\\nPour longtemps, t’éloigner\\nUn...   \n",
       "36478  Pour toi la maman\\nAvec tes enfants\\n\\nJe vais...   \n",
       "\n",
       "                                    titre  \n",
       "0                        La Perle De Dieu  \n",
       "1                Quand La Lune Se Dessine  \n",
       "2                         Nouveau Souffle  \n",
       "3               Ces Étoiles Qui Brillent.  \n",
       "4      Je Veux Dire Adieux Juste Instant.  \n",
       "...                                   ...  \n",
       "36474                               Union  \n",
       "36475           Un Voyage Pour Le Paradis  \n",
       "36476               Un Amour Sans Limites  \n",
       "36477                           Le Voyage  \n",
       "36478                     Un Petit Voyage  \n",
       "\n",
       "[36479 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Nettoyage de donnees<a id=\"part2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, il s'agissait de préparer les données pour la phase de training. Nettoyer, filtrer, faire toute opération nécessaire pour entamer sans difficulté la phase d'entrainement.\n",
    "\n",
    "1. Reduction de theme\n",
    "---\n",
    "Pour éviter d'avoir beaucoup de thème, parce qu'il y a plus de 200 thèmes, nous avons fait un choix arbitraire de  prendre le  thème le plus courant, soit une dizaine. Cette étape prépare la phase de training pour un modèle de classification des poèmes (prédire le thème d'un poème).  \n",
    "\n",
    "Nous avons donc choisi les 10 termes les plus courants, puis pour le reste de thème, nous avons fait un mapping en choissant parmi le 10 thèmes celui qui la plus grande similarité (cosinus).\n",
    "\n",
    "Pour ce faire, nous avons utilisé un modèle de word embedding entraînée sur un corpus en français pour vérifier la similarité. Le modèle de google entrainer sur les données en français ne marche pas, ce qui est tout à fait normal.\n",
    "\n",
    "\n",
    "2. Réduction de la taille des poèmes\n",
    "---\n",
    "\n",
    "Ce choix est fait après constat sur les modèles GPT-2 sur lequel on fine-tuning notre modèle. Ce modèle prend un texte de longueur maximale 728 pour le modèle en français et 1024 pour le modèle en anglais. Pour éviter de perdre de données, nous avons fixé une taille max des données à 1024 et le reste du texte constitue des nouvelles données. \n",
    "\n",
    "- Attention\n",
    "---\n",
    "Ce choix risque de porter biaise notre modèle, parce que certains textes n'auront pas tous leurs sens, du moins avoir le debut c'est deja bien, mais le reste du poème est-il vraiment pertinent comme données ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nous avons téléchargé 2 modèles d'embedding en français, un qui fait environ 1.5Go et un autre qui fait 4.5Go, un entraîné sur un grand corpus probablement. hypothese: le plus lourd est meilleur ?  Est-ce pertinent pour notre tâche ci d'avoir le meilleur possible ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = np.array([len (t)for t in dataset.texte])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.,  27., 128., 114., 152., 173., 208., 201., 165., 171., 136.,\n",
       "        102., 110.,  80.,  63.,  57.,  34.,  27.,  26.,  14.,  18.,  20.,\n",
       "          9.,  13.,   8.,   5.,   4.,   9.,   6.,   4.,   4.,   3.,   1.,\n",
       "          2.,   3.,   1.,   2.,   1.,   3.,   3.,   0.,   0.,   1.,   3.,\n",
       "          0.,   0.,   0.,   0.,   0.,   2.,   1.,   1.,   1.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   2.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   1.,\n",
       "          1.]),\n",
       " array([  10.  ,   85.44,  160.88,  236.32,  311.76,  387.2 ,  462.64,\n",
       "         538.08,  613.52,  688.96,  764.4 ,  839.84,  915.28,  990.72,\n",
       "        1066.16, 1141.6 , 1217.04, 1292.48, 1367.92, 1443.36, 1518.8 ,\n",
       "        1594.24, 1669.68, 1745.12, 1820.56, 1896.  , 1971.44, 2046.88,\n",
       "        2122.32, 2197.76, 2273.2 , 2348.64, 2424.08, 2499.52, 2574.96,\n",
       "        2650.4 , 2725.84, 2801.28, 2876.72, 2952.16, 3027.6 , 3103.04,\n",
       "        3178.48, 3253.92, 3329.36, 3404.8 , 3480.24, 3555.68, 3631.12,\n",
       "        3706.56, 3782.  , 3857.44, 3932.88, 4008.32, 4083.76, 4159.2 ,\n",
       "        4234.64, 4310.08, 4385.52, 4460.96, 4536.4 , 4611.84, 4687.28,\n",
       "        4762.72, 4838.16, 4913.6 , 4989.04, 5064.48, 5139.92, 5215.36,\n",
       "        5290.8 , 5366.24, 5441.68, 5517.12, 5592.56, 5668.  , 5743.44,\n",
       "        5818.88, 5894.32, 5969.76, 6045.2 , 6120.64, 6196.08, 6271.52,\n",
       "        6346.96, 6422.4 , 6497.84, 6573.28, 6648.72, 6724.16, 6799.6 ,\n",
       "        6875.04, 6950.48, 7025.92, 7101.36, 7176.8 , 7252.24, 7327.68,\n",
       "        7403.12, 7478.56, 7554.  ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(hist, bins= 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soit 20 % de donnee ont une longueur de plus de 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'Soit {int(((hist[hist>1000]).shape[0]/hist.shape[0])*100)} % de données ont une longueur de plus de 1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soit 2 % de donnee ont une longueur de plus de 2000\n"
     ]
    }
   ],
   "source": [
    "print(f'Soit {int(((hist[hist>2000]).shape[0]/hist.shape[0])*100)} % de données ont une longueur de plus de 2000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On peut voir qu'on peut quand même augmenter notre dataset de 20% environ.\n",
    "- Mais les textes de longueur plus de 2000 représentent 3%, pas très intéressant à traiter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_most_theme(filename='data.csv', n = 5):\n",
    "    \"\"\"\n",
    "    Récupère le n thèmes les plus fréquents\n",
    "\n",
    "    Args:\n",
    "        filname (str): nom du fichier contenant le dataFrame\n",
    "        n (int): le nombre de thèmes à retenir\n",
    "    Returns:\n",
    "        (list, list): un tuple de liste dont le premier contient le n thèmes le plus fréquents, et le deuxième contient tous les thèmes \n",
    "    \"\"\"   \n",
    "    dataset = pd.read_csv(filename)\n",
    "    all_theme = list(dataset.theme.values)\n",
    "    n_most_theme = Counter(all_theme).most_common()[:n]\n",
    "    n_most_theme = [v.split('/')[-1] for v,_ in n_most_theme]\n",
    "\n",
    "    return n_most_theme, list(set(all_theme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_theme, all_theme = get_n_most_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['absence', 'absolu', 'absurde', 'admiration', 'amant']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = '/home/saido/Documents/Master/NLP/Projet/embedding/model.bin'\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format(path_to_model, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ayant un nombre pas grand de thème, on peut se passer de cette question de similarité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_closest_theme(mots,w2v_model):\n",
    "    \"\"\"\n",
    "    Transformer les thèmes en n thèmes les plus fréquents.\n",
    "\n",
    "    Args:\n",
    "        mots (list): tous les thèmes à transformer\n",
    "        w2v_model (gensim): le modèle word2vec pour l'emebdding\n",
    "    Returns:\n",
    "        list: tous les thèmes transformés en n thèmes\n",
    "    \"\"\"   \n",
    "    all_best = dict()\n",
    "\n",
    "    for mot in mots:\n",
    "        best = ''\n",
    "        best_sim = 0\n",
    "        try:\n",
    "            for theme in most_theme:\n",
    "                # certains mot ne se trouve pas dans le dictionnaire, ou son mal ortographe. Pour ces derniers nous choisirons un them au hasard\n",
    "                res = w2v_model.similarity(theme,mot.split('/')[-1].split('-')[-1])\n",
    "                if res > best_sim:\n",
    "                    best_sim = res\n",
    "                    best = theme\n",
    "\n",
    "            all_best[mot] = best\n",
    "        except KeyError:\n",
    "            res = random.choice(most_theme)\n",
    "            print(f'the closest theme for {mot} is chose randomly ! => {res}')\n",
    "            all_best[mot] = res\n",
    "\n",
    "    return all_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "them_dic = get_most_closest_theme(all_theme, w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admiration': 'admiration',\n",
       " 'agir': 'absence',\n",
       " 'absolu': 'absolu',\n",
       " 'absurde': 'absurde',\n",
       " 'abondance': 'absence',\n",
       " 'absence': 'absence',\n",
       " 'age': 'amant',\n",
       " 'amant': 'amant',\n",
       " 'adoption': 'absence',\n",
       " 'acte': 'absurde'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "them_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('déraisonnable', 0.7194556593894958),\n",
       " ('embrouillamini', 0.6924372911453247),\n",
       " ('inconcevable', 0.6878689527511597),\n",
       " ('fatalité', 0.6861444115638733),\n",
       " ('autodestructrice', 0.685661792755127),\n",
       " ('dirions-nous', 0.6845793128013611),\n",
       " ('d’échappatoire', 0.6838091015815735),\n",
       " ('insinuer', 0.6832417845726013),\n",
       " ('non-sens', 0.6806569695472717),\n",
       " ('infâme', 0.680309534072876)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar('échappatoire', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réduction de la taille de poèmes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparaison de 2 modèles d'embedding\n",
    "\n",
    "Pour effectuer cette comparaison, on va prendre un mot, effectuer sont emebdding et calculer le cosinus de similarité pour sélectionner les meilleurs k, et voir intuitivement lequel nous donne de meilleurs résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce modèle prend beaucoup de temps à charger, ce qui peut être problématique pour une mise en prod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = '/home/saido/Documents/Master/NLP/Projet/embedding2/cc.fr.300.vec.gz'\n",
    "m = gensim.models.KeyedVectors.load_word2vec_format(path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Amour', 0.7595508098602295),\n",
       " ('amour.', 0.7153863906860352),\n",
       " ('amour.L', 0.6931040287017822),\n",
       " ('amour.Il', 0.6800874471664429),\n",
       " ('amour.Un', 0.6758425235748291),\n",
       " ('amour-amitié', 0.6670233011245728),\n",
       " ('amourL', 0.6663495302200317),\n",
       " ('amitié', 0.6645879149436951),\n",
       " ('amour.Mais', 0.6640422940254211),\n",
       " ('amour.Et', 0.6624426245689392)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.most_similar('amour'.split('-')[-1], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amour!', 0.8297661542892456),\n",
       " ('tendresse', 0.8126544952392578),\n",
       " ('amour-passion', 0.8055232167243958),\n",
       " ('amourfaire', 0.8044207096099854),\n",
       " ('l`amour', 0.7864792943000793),\n",
       " ('l’amour', 0.7811494469642639),\n",
       " ('drunc', 0.7783774137496948),\n",
       " ('abandonne-toi', 0.7736001014709473),\n",
       " ('espieglerie', 0.7726823091506958),\n",
       " (',amour', 0.7715793251991272)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar('amour'.split('-')[-1], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le premier modèle plus léger semble avoir des mots plus proches du mot amour, plus intuitifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admiration': 'admiration',\n",
       " 'agir': 'absence',\n",
       " 'absolu': 'absolu',\n",
       " 'absurde': 'absurde',\n",
       " 'abondance': 'absence',\n",
       " 'absence': 'absence',\n",
       " 'age': 'absence',\n",
       " 'amant': 'amant',\n",
       " 'adoption': 'absence',\n",
       " 'acte': 'absurde'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "them_dic = get_most_closest_theme(all_theme, m)\n",
    "them_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admiration': 'admiration',\n",
       " 'agir': 'absence',\n",
       " 'absolu': 'absolu',\n",
       " 'absurde': 'absurde',\n",
       " 'abondance': 'absence',\n",
       " 'absence': 'absence',\n",
       " 'age': 'amant',\n",
       " 'amant': 'amant',\n",
       " 'adoption': 'absence',\n",
       " 'acte': 'absurde'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "them_dic = get_most_closest_theme(all_theme, w2v_model)\n",
    "them_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultat similaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelques hypothèses partie 3\n",
    "\n",
    "- Un modèle entrainé sur les données en français marcherait mieux que celui entrainé avec des données dans une autre langue (anglais par exemple)\n",
    "- Un modèle sur entrainer devrait générer de la poésie que celui non sur-entrainer\n",
    "- Générer du texte avec un modèle entrainer et non entrainer pour comparer les résultats.\n",
    "\n",
    "- Le modèle GPT-2 (Utilise l'architecture de l'état de l'art, Transformers) étant entrainé sur un grand dataset devait mieux marcher qu'un RNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération de quelques exemples avec les modèles entrainés <a id=\"part4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va générer quelques textes à partir de 2 ou 3 mots avec différents modèles pour voir ce que nous obtenons comme résultat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN model (10 epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Amour et haine\n",
    "---\n",
    "Amour et haine farouche ! Un monde inconnu et la vie pour un cadeau adressé Qu’elle me bouleverse Si tu me sens de mes nuits J’attend au Clandestin, Je ne savais pas, avec mes pensées aliénantes Je le peux Je te vois encore que je pense ? Pourquoi ai-je fais un homme tu a mis des mots qui remettent de ta révérence De tes envies sans faisant foi ni orgueilleux, et les écritures, ne ne pas se font vibrer, pas. Moi qui assemble mes yeux, Sans toi Tu m’as inventé de ma vie Tu te reconnaitras… j’ai le satisfaire de ton corps accidenté Il"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Je suis fou amour\n",
    "---\n",
    "Je suis fou amour ? J’ai envie du temps De la joie et le temps de sa robe d’un coup de la vie Et si tu ne sais quoi. pas de la suite que le monde je me sens de te rejoindr Repose dans le comptoir, le tenancier Je suis de sa jouissance, La mort me rend dans le placard, dans le pêché. je le sais. de te voir Ton image Tristesse, ses pas. Part, moi Se perdant nos supplications Nul qui ont été fou… de la soirée, et les gardiens Le silence est si beau Gris, de desserts, De la nuit Tu me souviens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT model No fine tune\n",
    "\n",
    "- Amour est un oiseau rebel\n",
    "---\n",
    "L'amour est un oiseau rebel ; une seule parole peut m' élever jusqu' à Dieu de cette vie solitaire mais qui, après l' avoir donnée aux vivants avec joie, s' y réfugie sous une douce tyrannie, de même jusqu' à sa mort. Je te demande seulement ce qui te chagrine parce quel que vous soyez ce qui t'étonne pas de la politique. LDLC pour les petits epub de toute catégorie : à vous de venir découvrir la plateforme du leader et ceux déjà en activité ainsi que sa politique commerciale avec les nouveaux lecteurs qui vont se rajouter prochainement. Dans mon souvenir d' amateur de cinéma, c' étaient en fait la première trilogie du réalisateur suédois Carl Ove Andersen, ainsi que la 2. Avec les températures au thermomètre qui descendent jusqu' aux 4, 5 pour 10 degrés, cela fait beaucoup : la nourriture qui mijote devient une denrée de première nécessité. En raison des incertitudes liées à notre analyse des prix, aucune confirmation de commercialisation n & apos ; a pu être formulée par Solucom ni auprès de ses collaborateurs directs ou indirects. Vous trouverez facilement la petite annonce de Equipement de vacances d' aide aux particuliers de la catégorie de Voiture pour vos annonces de Véhicules sur Mantes la Jolie. J' avais vu juste alors de parler de celui ou de celle qui m' intéressait ici plus encore avec quelques infos et des infos complémentaires sur chacun d' entre eux que les autres. Si l' action du joueur augmente considérablement à mesure,\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Science sans conscience n'est que ruine de l'ame \n",
    "---\n",
    "Science sans conscience n'est que ruine de l'ame ʾHan hījūs, dont aucun autre pays nen jouit a fait fortune. Une fois qu' on y a pensé une deuxième couche vous les déplacez. Je vais faire ce chemin qui permet à mon cheval de revenir au moins en forme le 1 juin prochain lors des essais de dimanche prochain avec un système à puce et des réglages dans lequel je pourrai continuer pendant cinq mois et je verrai tout le temps que j' aimerai retrouver en course au prochain grand tour final en 2015 pour préparer de belle épreuve.Pensez donc à l avenir, nous pensons au championnat d ouverture qu est le GP d Autriche mais je crois qu à cette heure la dernière épreuve pour moi sera vraiment d ici la moitié début Novembre afin de vous motiver si le besoin me tenaille d ores et déjà avant même les 3e et 4e manche mais le week-end précédant mon Tour de Suisse vous y serez bien souvent déjà.Via mes blogs photos des vacances en Argentine, ce sont des images superbes par moment. Comme les femmes plus que jamais il leur est de l ordre d un système en jeu, elle va avoir à lutter, à l aide du pouvoir matériel de celui qu elle croit représenter pour de bon, par exemple dans une ville d Amérique Latine au statut relativement récent. Comme tout, son caractère de prédateur avait d' ores et déjà laissé des traces chez nous. Son nouveau design offre tous leurs talents dans la manipulation des\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La haine que l'on ressent\n",
    "---\n",
    "La haine que l'on ressent ourdît au lieu que la liberté de presse vous donnast un libre appui à votre cause. Le film est basé à Melbourne et donne de nombreuses indications sur l' identité de tous les jeunes adolescents se produisant aux Transphrase : il s' agit soit à l' arrière d' une limousine décapotable blanche, avec au volant des passagers une sorte \" doo grrrrnt hahahohohmmha oui, c' est pour rire (... ahhh! ) De toute facon, les francais disent : tu peux plus pas nous envoyer à la mer sauf nous si on fait des gaffes ou quoi \" Et tu les as un peu forcé a le suivre meme qu \" 1 semaine aprés y a deja des regains de deboires.. alors au point où vous m ecoutiez jerais pas.. il est venu voir les fg en se branlant le bougre ( lol.. ça le calmeras! ) La ville de Rennes organise chaque printemps sur les pelouses du parc Jean Moulin sa grande \" Grande Rencontre de Ville-Égalité 2016 \" où les élus locaux, étudiants ou anciens, du personnel pénitentiaire ainsi que des enseignants chercheurs doivent débattre, débattre, échanger et réfléchir autour d' enjeux relatifs à la question des droits au service des habitants âgés. Ils sont donnés sous réserve de modifications depuis leur mise en oeuvre. J' écris d' une certaine façon ma propre manière de voir la littérature, ce qui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT model fine tune (2 epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Amour est un oiseau rebel\n",
    "---\n",
    "L'amour est un oiseau rebelote, son cœur s’illuminise\n",
    "Le ciel est la beauté de ma chair siltlore…\n",
    "La mer en ses océans roses, devient mon océan de douceur, et si doux, en nous l’oubliant nous perdrions à jamais dans ces sables mouvants d’ailleurs.\n",
    "Il nous tend un livre à foison, car il parle avec amour, son bonheur quille il te donne et ses joies que j’irais aux coins de toutes nos envies…\n",
    "Il voudrait chanter comme le dernier poème de ta mère avec le soleil il me dévoile pour l’année 2016 en plein été, et tous sa magnifique couleur des boutons bleus pour faire naître et embellir sa chevelure châine pour mettre fin en moins à votre solitude tant le long, je me perds souvent pour quelques minutes tout l’espace me quitte. Dans son océan comme des naufragés, tu es devenu l’alice qui fait naître et meurt les rayons les rayons, mes cheveux au bout d’une flèche au sein.. Mais où le soleil luit alors de l’éclairement, quand il ne fait pas gris\n",
    "Je n’ai rien, dans un champ de lavande dans mon pays d’un paradis sur loc. cogne! le soleil est à l’âme jure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Science sans conscience n'est que ruine de l'ame \n",
    "---\n",
    "Science sans conscience n'est que ruine de l'ame ossique\n",
    "Eveil sans fin ne veut etre ke dans sa naissance alorquellous les heures\n",
    "Univers d’un momie a vie sans trencunté d’un moment!\n",
    "Enneigant, les heures perdues d’un ecrle humain pour vivre\n",
    "Humains qui l’attouffrent a vie!\n",
    "Tout ces qui a copar\n",
    "Un jour le mot d’adieu n’a trouver personne et l amour il en est de plus beau!\n",
    "Feignant tout la beauté avec force mais qui aime en vain mais la fauté est que le desordre il doit assumer se garer mais rien de plus ou ca. c est tout mon choix si en aucun temps a caprendre…!!\n",
    "Douleur noire mais pour rien le noir l’espoir nera nous\n",
    "Le mot lumière et l espoir car rien ne vit encore car ici et bien la c est le mal, notre chemin… et là encore…!!!!\n",
    "L’importance nous a eu aussi, nous avons eu une question sur la fin qui n’a jamais était si presager : il n existe pas! pourquoi avons on oublié notre dieu??� nous devons accepter d aimer dans le temps en sachant nos destin si parfois on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La haine que l'on ressent\n",
    "---\n",
    "La haine que l'on ressent 😟���A l attention, que vous prenez pour du vrai,\n",
    "Egaux cachés\n",
    "Riqués et maudits, ceux là sont aussi fort?\n",
    "\n",
    "Des mots, rien que mes poings ne font que dire,\n",
    "J attends leurs échos sur papier, mais vous restez sourds,\n",
    "Tenter, par métrise sans réfléchir et d empêcher,\n",
    "En fait, des années s enviéent.\n",
    "Laissent la cruauté des victimes venir sans aucun doute les aider, ils ne le seront vraiment que pour mieux les ignorer? C’Est ce la souffrance à l air de le calmer??\n",
    "Dans des contrées d une extrêmerocité! Mais peut-être encore pire, on voudrait nous emprisonner. /_�CÔLYPILAm�~❘�œ ⚙�PLAFERYÉÇÇ ÇAYOU ´ TU… FOUTAIN TU –TAS ’︫ ‫\n",
    "Ce message n émanant que d amis e – et autres qui ne demandent rien…, nVi-fez ni OI, n’ont aucun souci d argent, ni aucuns souci…\n",
    "Alors pour l’appel au partage tout oublier c est bon signe de tout•�. L amour et le partage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion  et analyses des résultats <a id=\"part5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Ce projet est loin d'être fini, et a plein de pistes d'amélioration. Avec les moyens à notre disposition, nous avons pu entrainer 2 modèles pour générer les poèmes. Les résultats ne sont pas très satisfaisant comme on l'aurait voulu, mais certaines phrases sont originales. \n",
    "\n",
    "Nous nous sommes butés au problème de ressources, entrainer un modèle jusqu'au but nécessite une machine puissante pour avoir un résultat concluant ; nous avons utilisé google colab mais nous étions limités pour son utilisation (au bout de quelques heures d'entrainement, plus accès au GPU). \n",
    "\n",
    "Aussi étonnant, le modèle RNN que nous avons entrainé from scratch a donné des résultats assez surprenants. Si le modèle est entrainement avec les bons hyperparametres les résultats seront meilleurs que ce que nous avons obtenu (epoch !!!).\n",
    "\n",
    "On aurait pu collecter des plus de données pour constituer un dataset plus grand que ce qu'on a eu, tester les hypothèses, choisir les bons hyperparametre, ... voici là quelques pistes pour améliorer.\n",
    "\n",
    "Le modèle GPT-2 que nous avons fine tune n'est peut-être pas le meilleur, nous aurions eu sûrement un meilleur modèle si la tache est celle de générer les poèmes en anglais, nous avons donc constaté ce manque pour la langue française (dataset, modele transformers), ....\n",
    "\n",
    "En espérant que ce projet inspirerait plus d'un, nous vous invitons à tester ce modèle et l'améliorer, et l'utiliser à votre sauce.\n",
    "\n",
    "Enjoy !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
